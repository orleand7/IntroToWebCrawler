{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버 뉴스 기사 웹 크롤링\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib.request\n",
    "\n",
    "#크롤링 결과 파일 이름\n",
    "OUTPUT_FILE_NAME = 'output.txt'\n",
    "#원하는 기사의 주소\n",
    "URL='https://news.naver.com/main/read.nhn?oid=421&sid1=101&aid=0003811754&mid=shm&mode=LSD&nh=20190130121410'\n",
    "\n",
    "#크롤링 함수\n",
    "def get_text(URL):\n",
    "    source_code_from_URL = urllib.request.urlopen(URL)\n",
    "    soup = BS(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='articleBodyContents'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text\n",
    "\n",
    "#메인 함수\n",
    "def main():\n",
    "    open_output_file = open(OUTPUT_FILE_NAME, 'w')\n",
    "    result_text = get_text(URL)\n",
    "    open_output_file.write(result_text)\n",
    "    open_output_file.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output.txt 파일을 보면 기호와 코드로 복잡하게 얽으니, 텍스트를 정제해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 정제 모듈\n",
    "import re\n",
    "\n",
    "INPUT_FILE_NAME = 'output.txt'\n",
    "OUTPUT_FILE_NAME = 'output_cleaned.txt'\n",
    "\n",
    "#정제 함수\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]',\n",
    "                          '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def main():\n",
    "    read_file = open(INPUT_FILE_NAME, 'r')\n",
    "    write_file = open(OUTPUT_FILE_NAME, 'w')\n",
    "    text = read_file.read()\n",
    "    text = clean_text(text)\n",
    "    write_file.write(text)\n",
    "    read_file.close()\n",
    "    write_file.close()\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html 지정을 변경하는 것으로 다른 플랫폼의 뉴스 기사도 크롤링이 가능합니다.\n",
    "\n",
    "DAUM 뉴스기사도 같은 방법으로 크롤링 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import urllib.request\n",
    "\n",
    "#크롤링 결과 파일 이름- 네이버와 구분지어 줍시다\n",
    "OUTPUT_FILE_NAME = 'output_DAUM.txt'\n",
    "#원하는 기사의 주소\n",
    "URL='https://news.v.daum.net/v/20190130120005732?rcmd=rn'\n",
    "\n",
    "#크롤링 함수\n",
    "def get_text(URL):\n",
    "    source_code_from_URL = urllib.request.urlopen(URL)\n",
    "    soup = BS(source_code_from_URL, 'lxml', from_encoding='utf-8')\n",
    "    text = ''\n",
    "    for item in soup.find_all('div', id='harmonyContainer'):\n",
    "        text = text + str(item.find_all(text=True))\n",
    "    return text\n",
    "\n",
    "#메인 함수\n",
    "def main():\n",
    "    open_output_file = open(OUTPUT_FILE_NAME, 'w')\n",
    "    result_text = get_text(URL)\n",
    "    open_output_file.write(result_text)\n",
    "    open_output_file.close()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 정제 모듈|\n",
    "import re\n",
    "\n",
    "#구분된 파일이름으로 작성\n",
    "INPUT_FILE_NAME = 'output_DAUM.txt'\n",
    "OUTPUT_FILE_NAME = 'output_DAUM_cleaned.txt'\n",
    "\n",
    "#정제 함수\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub('[a-zA-Z]', '', text)\n",
    "    cleaned_text = re.sub('[\\{\\}\\[\\]\\/?.,;:|\\)*~`!^\\-_+<>@\\#$%&\\\\\\=\\(\\'\\\"]',\n",
    "                          '', cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def main():\n",
    "    read_file = open(INPUT_FILE_NAME, 'r')\n",
    "    write_file = open(OUTPUT_FILE_NAME, 'w')\n",
    "    text = read_file.read()\n",
    "    text = clean_text(text)\n",
    "    write_file.write(text)\n",
    "    read_file.close()\n",
    "    write_file.close()\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
